{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>K Nearest Neighbor Classification</center></h1>\n",
    "\n",
    "The goal of this tutorial is to develop your understanding of a basic Machine Learning classification model and learn some basic area of machine learning like supervised learning. It is necessary to not only understand the mathematics behind the models but also to know how to convert that knowledge into code that can work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By the end of this tutorial, youâ€™ll have learned:\n",
    "\n",
    "   - What KNN is\n",
    "   - KNN Algorithm\n",
    "   - How to implement KNN in Python, step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Supervised learning in machine learning is the task of learning a funcion that maps some inputs to outputs based on some input-output pair. It infers a function from labeled training data consisting of a set of training examples. In supervised learning we are given labeled data with which we can compare our model's predictions with. A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples.\n",
    "\n",
    "Classification is an example of supervised learning. We will be looking at one of the most basic classification algorithm called K Nearest Neighbor (KNN) in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Classification?\n",
    "\n",
    "In machine learning, classification is the problem of identifying to which of a set of categories a new observation belongs to, on the basis of a training set of data containing observations whose category membership is known (is labeled). For example assigning an email spam or not spam is an example of classification. or Identifying a patient to have cancer or not is also an example of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor\n",
    "\n",
    "K-Nearest Neighbors, or KNN is one of the simplest machine learning algorithms and is commonly used in many cases which are rather simple. KNN is a non-parametric algorithm which means that it doesn't make any assumptions about the data. KNN makes its decision based on distance of one example from others. This distance can simply be Euclidean distance. Also, KNN is a lazy algorithm which means that there is little to no training phase. Therefore, new data can be immediately classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages and Disadvantages of KNN\n",
    "\n",
    "##### Advantages\n",
    "   - Makes no assumptions about the data.\n",
    "   - Simple algorithm.\n",
    "   - Used for classification easily.\n",
    "    \n",
    "##### Disadvantages\n",
    "   - A lot of memory is required.\n",
    "   - Is very sensitive to irrelevant features.\n",
    "   - Also, very sensitive to the scale of data we are computing the distance with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm of KNN\n",
    "\n",
    "   - Pick some value of k i.e. 3, 5 or 7.\n",
    "   - Choose k nearest neighbor of the new data point according to its Eucliean distance.\n",
    "   - For each data point in test we do.\n",
    "        - Calculate the distance between test data and each row of training data with the help of Euclidean distance.\n",
    "        - Now, sort in ascending order according to the distance computed.\n",
    "        - Choose top k from the distance array.\n",
    "        - Now, assign a class to the test sample based on most frequent class of these rows.\n",
    "   - End Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let's see an example to understand better.\n",
    "Suppose we have some data which is plotted as.\n",
    "\n",
    "![title](one.png)\n",
    "\n",
    "You can see that there are two classes in data one is red and other is blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider that we have a test data point (black colored) and we have to predict whether it belongs to red class or the blue class. \n",
    "We will compute Euclidean distance of test point with k nearest neighbors. Here k = 3\n",
    "\n",
    "![title](two.png)\n",
    "\n",
    "Now, we have computed the distance of test point with the neighbors and can see that it is much closer to the red class. Hence \n",
    "this data point will be classified as red class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation using python\n",
    "\n",
    "These are some of the essential libraries that are needed to use some built-in functionalities provided by python. Some well-known libraries are like Numpy, sklearn.\n",
    "\n",
    "Sklearn provide a lot of support for machine learning algorithms. We will be using GridSearchCV funstion provided by sklearn which can be very useful.\n",
    "\n",
    "##### Grid Search CV\n",
    "\n",
    "Grid search is the process of performing hyper-parameter tuning in order to determine the optimal values of the hyper-parameter for a given model. This is significant as the performance of the entire model is based on the hyper parameter values specified.\n",
    "\n",
    "##### Why use it?\n",
    "\n",
    "Chooing best parameters in machine learning process is like a nightmare for practioners. There are libraries that have been implemented, such as GridSearchCV of the sklearn library, in order to automate this process and make the process bit easier for ML practioners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN function\n",
    "\n",
    "Here we will create a custom KNN method with 5 parameters i.e. training examples, training labels, test examples, test label and a list of possible values of k to train on.\n",
    "\n",
    "First, we create an object of KNeighborsClassifier() we imported from sklearn.\n",
    "Then we created a dictionary named parameters and stored the list k in it.\n",
    "Third step is to pass the classifier i.e. knn and the paramters to GridSearchCV and fit this model on training data\n",
    "GridSearchCV will give us best parameter of training and we will make predictions on test data using that paramter. \n",
    "model.predict() predicts the labels on test data and we can check its accuracy by the function accuracy_score() we imported using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(x_tr, y_tr, x_te, y_te, k):\n",
    "    print('\\nTraining Started for values of k', [each for each in k],'.......')\n",
    "    # Create an knn object using imported KNeighborsClassifier() from sklearn\n",
    "    knn = KNeighborsClassifier()\n",
    "    # parameters i.e. k neighbors list\n",
    "    parameters = {'n_neighbors':k}\n",
    "    \n",
    "    # Training the model\n",
    "    model = GridSearchCV(knn, param_grid = parameters, cv=3)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    print('Best value of k is ',model.best_params_)\n",
    "    \n",
    "    # Making Predictions on test data\n",
    "    print('\\nPredicting on Test data.......')\n",
    "    pred = model.predict(x_te)\n",
    "    print('\\nAccuracy of model on test is', accuracy_score(y_te, pred)*100,'%')\n",
    "    return accuracy_score(y_te, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This custom method is irrelevant for this tutorial. It just some pre-processing done on the data that I am using for KNN classification which is Google Playstore Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_preProcess():\n",
    "    # Processing Apps.csv\n",
    "    data = pd.read_csv('apps.csv')\n",
    "    columns = ['App', 'Category', 'Rating', 'Size', 'Type', 'Price', 'Genres']\n",
    "    data[columns]\n",
    "    new_data = data[columns].copy()\n",
    "    new_data = new_data.fillna(0)\n",
    "    for each in range(0, len(new_data['Rating'])):\n",
    "        if new_data['Rating'][each] == 0:\n",
    "            new_data.at[each, 'Rating'] = new_data['Rating'].mean()\n",
    "    price_list = [float(each.replace(\"$\",\"\")) for each in new_data.Price]\n",
    "    new_data.Price = price_list\n",
    "    \n",
    "    # Processing User_reviews.csv\n",
    "    data2 = pd.read_csv('user_reviews.csv')\n",
    "    column = ['App', 'Sentiment_Polarity', 'Sentiment_Subjectivity', 'Sentiment']\n",
    "    data2[column]\n",
    "    new_data2 = data2[column].copy()\n",
    "    \n",
    "    # Merging the two datasets into one final dataset\n",
    "    df = new_data.merge(new_data2, on='App')\n",
    "    df.Sentiment = df['Sentiment'].replace(to_replace='Positive', value=1).replace(to_replace='Negative', value=-1).replace(to_replace='Neutral', value=0)\n",
    "    df.Sentiment_Polarity = df.Sentiment_Polarity.fillna(df.Sentiment_Polarity.mean())\n",
    "    df.Sentiment_Subjectivity = df.Sentiment_Subjectivity.fillna(df.Sentiment_Subjectivity.mean())\n",
    "    df = df[df['Sentiment'].notna()]\n",
    "    df.Type = df['Type'].replace(to_replace='Free', value=1).replace(to_replace='Paid', value=0)\n",
    "    df = df.drop(['Size'], axis=1)\n",
    "    \n",
    "    # Separating dataset into samples and labels\n",
    "    X = df.iloc[:, 0:7]\n",
    "    y = df.iloc[:, 8:9]\n",
    "    \n",
    "    # Encoding the dataset \n",
    "    X = pd.get_dummies(X)\n",
    "    print('\\nFinished pre-processing data....')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a main function and all the processing is done in this function. Like we will call the above created methods in this main function. Also, we are applying some data normalization techiques in this function and calling the custom function on our data.\n",
    "\n",
    "You might not need normalization according to the data you use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished pre-processing data....\n",
      "\n",
      "Training Started for values of k [3, 5, 7] .......\n",
      "Best value of k is  {'n_neighbors': 7}\n",
      "\n",
      "Predicting on Test data.......\n",
      "\n",
      "Accuracy of model on test is 86.07469428225184 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X, y = Data_preProcess()\n",
    "    # Splitting the data into Train and Test data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    \n",
    "    # Normalizing the data\n",
    "    sc_X = StandardScaler()\n",
    "    x_train = sc_X.fit_transform(x_train)\n",
    "    x_test = sc_X.transform(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    #Running KNN\n",
    "    k = [3,5,7]\n",
    "    acc = KNN(x_train[:5000], y_train[:5000].ravel(), x_test, y_test, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an Accuracy of 86 % which very decent for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
